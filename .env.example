# RLM Explained - Environment Variables
# Copy this file to .env and configure your preferred provider
# Run `make setup` for interactive configuration

# ============================================================================
# LLM PROVIDERS
# ============================================================================
# Configure ONE of the following providers. The setup wizard (`make setup`)
# will help you choose and configure the right one for your needs.

# ----------------------------------------------------------------------------
# OpenAI (GPT-4, GPT-4o, GPT-3.5)
# Get your key at: https://platform.openai.com/api-keys
# ----------------------------------------------------------------------------
# OPENAI_API_KEY=sk-...

# ----------------------------------------------------------------------------
# Anthropic (Claude 3.5, Claude 3)
# Get your key at: https://console.anthropic.com/settings/keys
# ----------------------------------------------------------------------------
# ANTHROPIC_API_KEY=sk-ant-...

# ----------------------------------------------------------------------------
# Google Gemini (Gemini Pro, Gemini Flash)
# Get your key at: https://aistudio.google.com/apikey
# ----------------------------------------------------------------------------
# GEMINI_API_KEY=...

# ----------------------------------------------------------------------------
# Cerebras (Llama-based models with fast inference)
# Get your key at: https://cloud.cerebras.ai/
# ----------------------------------------------------------------------------
# CEREBRAS_API_KEY=...

# ----------------------------------------------------------------------------
# OpenRouter (Access multiple providers through one API)
# Get your key at: https://openrouter.ai/keys
# ----------------------------------------------------------------------------
# OPENROUTER_API_KEY=sk-or-...

# ----------------------------------------------------------------------------
# Portkey (AI gateway with observability and routing)
# Get your key at: https://app.portkey.ai/
# ----------------------------------------------------------------------------
# PORTKEY_API_KEY=...

# ----------------------------------------------------------------------------
# Azure OpenAI (OpenAI models on Azure infrastructure)
# Configure in Azure Portal: https://portal.azure.com/
# ----------------------------------------------------------------------------
# AZURE_OPENAI_API_KEY=...
# AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
# AZURE_OPENAI_DEPLOYMENT=your-deployment-name

# ----------------------------------------------------------------------------
# LiteLLM (Unified interface for 100+ LLMs)
# Docs: https://docs.litellm.ai/
# Note: LiteLLM uses the API keys of the underlying providers above
# ----------------------------------------------------------------------------

# ----------------------------------------------------------------------------
# vLLM (Self-hosted inference server)
# Docs: https://docs.vllm.ai/
# Note: No API key required, just specify your server URL
# ----------------------------------------------------------------------------
# VLLM_BASE_URL=http://localhost:8000/v1
